% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_eda_dash.R
\name{spark_eda_dash}
\alias{spark_eda_dash}
\title{An EDA Dashboard Builder for SparklyR updated \cr}
\usage{
spark_eda_dash(sparklyr_table, hist_num_buckets = 10L,
  hist_include_null = FALSE, hist_decimal_places = 2L,
  desc_decimal_places = 2L)
}
\arguments{
\item{sparklyr_table}{is the spark table you will pass to the function. You can pass using a dplyr spark table (tbl).}

\item{hist_num_buckets}{(default=10L) will set the number of buckets for the Spark Histograms (on each numeric column). The default is 10 buckets  (set with 10L)}

\item{hist_include_null}{(default=FALSE) if TRUE will include a column with the null counts for each field in the histograms}

\item{hist_decimal_places}{(default = 2L) controls the number of decimals values to round for histograms bucketed (if any)}

\item{desc_decimal_places}{(default = 2L) controls the number of decimals}
}
\description{
It is adivsed to drop time/array/other columns (or those with nested datatypes) before running.
}
\details{
Important package requirements: \cr
Download the required jar at \href{www.gabechurch.com/sparkEDA}{www.gabechurch.com/sparkEDA}  (default future integration is in the works) \cr
\cr
Example selection of a spark table and graph\cr
\code{spark_table = tbl(sc, sql("select * from db.stock_samples_20m limit 100"))} \cr
\code{spark_hist(spark_table, 20L)}
}
