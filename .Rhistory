conf$spark.offHeap.endabled="true"
conf$spark.memory.offHeap.size="1G"
sc = spark_connect(master = "yarn-client", config = conf, version = '2.3.2')
spark_connection_is_open(sc)
knitr::opts_chunk$set(echo = TRUE)
spark_disconnect_all()
spark_disconnect_all()
library(sparklyr)
library(dplyr)
Sys.setenv(SPARK_HOME="/usr/hdp/3.1.0.0-78/spark2")
conf = spark_config()
conf$'sparklyr.jars.default'= "/home/gchurch/R/sparkeda_2.11-2.01.jar"
conf$'sparklyr.shell.executor-memory' = "4g"
conf$'sparklyr.shell.driver-memory' = "70g"
conf$spark.executor.cores = 2
#conf$spark.executor.memory = "5G"
#conf$spark.yarn.am.cores = 2
#conf$spark.yarn.am.memory = "2G"
conf$spark.executor.instances=20
conf$sparkmaximizeResourceAllocation = "true"
#testing adding
conf$spark.io.compression = "Snappy" #serialization
conf$spark.serializer="org.apache.spark.serializer.KryoSerializer"
conf$spark.kryo.unsafe="true"
#### pulled conf$spark.serializer.objectStreamReset=
#Shuffle settings (must have enabled for dynamic allocation)
conf$spark.shuffle.service.enabled="true"
conf$spark.shuffle.compress="true"
conf$spark.shuffle.consolidateFiles="true" #adding dynamic allocation
conf$spark.dynamicAllocation.enabled = "false"
conf$spark.dynamicAllocation.initialExecutors=0
conf$spark.dynamicAllocation.maxExecutors=30
conf$spark.dynamicAllocation.minExecutors=0
conf$spark.cores.max=2
#other
conf$spark.default.parallelism=10
#conf$spark.memory.fraction=0.6
#conf$spark.memory.storageFraction=0.5
#heap
conf$spark.offHeap.endabled="true"
conf$spark.memory.offHeap.size="1G"
sc = spark_connect(master = "yarn-client", config = conf, version = '2.3.2')
library(sparklyr)
library(dplyr)
Sys.setenv(SPARK_HOME="/usr/hdp/3.1.0.0-78/spark2")
conf = spark_config()
conf$'sparklyr.jars.default'= "/home/gchurch/R/sparkeda_2.11-2.01.jar"
conf$'sparklyr.shell.executor-memory' = "4g"
conf$'sparklyr.shell.driver-memory' = "70g"
conf$spark.executor.cores = 2
#conf$spark.executor.memory = "5G"
#conf$spark.yarn.am.cores = 2
#conf$spark.yarn.am.memory = "2G"
conf$spark.executor.instances=20
conf$sparkmaximizeResourceAllocation = "true"
#testing adding
conf$spark.io.compression = "Snappy" #serialization
conf$spark.serializer="org.apache.spark.serializer.KryoSerializer"
conf$spark.kryo.unsafe="true"
#### pulled conf$spark.serializer.objectStreamReset=
#Shuffle settings (must have enabled for dynamic allocation)
conf$spark.shuffle.service.enabled="true"
conf$spark.shuffle.compress="true"
conf$spark.shuffle.consolidateFiles="true" #adding dynamic allocation
conf$spark.dynamicAllocation.enabled = "false"
conf$spark.dynamicAllocation.initialExecutors=0
conf$spark.dynamicAllocation.maxExecutors=30
conf$spark.dynamicAllocation.minExecutors=0
conf$spark.cores.max=2
#other
conf$spark.default.parallelism=10
#conf$spark.memory.fraction=0.6
#conf$spark.memory.storageFraction=0.5
#heap
conf$spark.offHeap.endabled="true"
conf$spark.memory.offHeap.size="1G"
sc = spark_connect(master = "yarn-client", config = conf, version = '2.3.2')
spark_connection_is_open(sc)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.SparkEDA")
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper")
tbl_cache(sc, "sample_data.movielens_ratings_20m")
movie_ratings = tbl(sc, "sample_data.movielens_ratings_20m")
tbl_cache(sc, "sample_data.movielens_ratings_20m")
movie_ratings = tbl(sc, "sample_data.movielens_ratings_20m")
tbl_cache(sc, "sample_data.movielens_ratings_20m")
movie_ratings = tbl(sc, "sample_data.movielens_ratings_20m")
raw_df = spark_dataframe(movie_ratings)
#spark_df = sdf_register(raw_df)
histograms = sparklyr::invoke(classTest, "histBackEnd", raw_df) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", dataFrame=raw_df) #%>%
histograms = sparklyr::invoke(classTest, "temp"") #%>%
#sparklyr::invoke("histBackEnd", raw_df, 10)
histograms = sparklyr::invoke(classTest, "temp") #%>%
#sparklyr::invoke("histBackEnd", raw_df, 10)
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd") #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper", "histBackEnd") #%>%
histograms = sparklyr::invoke() #%>%
raw_df = spark_dataframe(movie_ratings)
#spark_df = sdf_register(raw_df)
histograms = sparklyr::invoke(classTest, "histBackEnd", raw_df) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", raw_df, 10) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", (raw_df, 10) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", (raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", (raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", (raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", Seq(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", List(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd", list(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd") %, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "histBackEnd") #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke("com.gabechurch.sparklyRWrapper.histBackEnd", raw_df) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static("com.gabechurch.sparklyRWrapper.histBackEnd", raw_df) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke(classTest, "com.gabechurch.sparklyRWrapper.histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
histograms = sparklyr::invoke_static(classTest, "histBackEnd", raw_df, 10) #, list(raw_df, 10)) #%>%
rContainer = sparklyr::invoke_new(sc, "SparkHello.HelloWorld") %>% invoke("histBackEnd", raw_df, 10)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke_static("histBackEnd", raw_df)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df, 10)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df, 10)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df, 10)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df, 10L)
classTest = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df, 10L)
collected = classTest %>% invoke("collect")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggplot2)
#collected %>% map(function(x)    )
length(collected)
library(ggplot2)
output = collected %>% map(function(x) length(x)   )
library(ggplot2)
library(purrr)
output = collected %>% map(function(x) length(x)   )
#length(collected)
collected = classTest %>% invoke("collect")
library(sparklyr)
library(dplyr)
Sys.setenv(SPARK_HOME="/usr/hdp/3.1.0.0-78/spark2")
conf = spark_config()
conf$'sparklyr.jars.default'= "/home/gchurch/R/sparkeda_2.11-2.01.jar"
conf$'sparklyr.shell.executor-memory' = "4g"
conf$'sparklyr.shell.driver-memory' = "70g"
conf$spark.executor.cores = 2
#conf$spark.executor.memory = "5G"
#conf$spark.yarn.am.cores = 2
#conf$spark.yarn.am.memory = "2G"
conf$spark.executor.instances=20
conf$sparkmaximizeResourceAllocation = "true"
#testing adding
conf$spark.io.compression = "Snappy" #serialization
conf$spark.serializer="org.apache.spark.serializer.KryoSerializer"
conf$spark.kryo.unsafe="true"
#### pulled conf$spark.serializer.objectStreamReset=
#Shuffle settings (must have enabled for dynamic allocation)
conf$spark.shuffle.service.enabled="true"
conf$spark.shuffle.compress="true"
conf$spark.shuffle.consolidateFiles="true" #adding dynamic allocation
conf$spark.dynamicAllocation.enabled = "false"
conf$spark.dynamicAllocation.initialExecutors=0
conf$spark.dynamicAllocation.maxExecutors=30
conf$spark.dynamicAllocation.minExecutors=0
conf$spark.cores.max=2
#other
conf$spark.default.parallelism=10
#conf$spark.memory.fraction=0.6
#conf$spark.memory.storageFraction=0.5
#heap
conf$spark.offHeap.endabled="true"
conf$spark.memory.offHeap.size="1G"
sc = spark_connect(master = "yarn-client", config = conf, version = '2.3.2')
tbl_cache(sc, "sample_data.movielens_ratings_20m")
movie_ratings = tbl(sc, "sample_data.movielens_ratings_20m")
raw_df = spark_dataframe(movie_ratings)
#spark_df = sdf_register(raw_df)
histograms = sparklyr::invoke_new(sc, "com.gabechurch.sparklyRWrapper") %>% invoke("histBackEnd", raw_df, 10L)
collected = classTest %>% invoke("collect")
collected = histograms %>% invoke("collect")
library(ggplot2)
library(purrr)
counts = collected %>% map(function(x) length(x)   )
#length(collected)
counts
collected[3]
carset = data("cars")
data("cars")
head(cars)
data("mpg")
head(mpg)
ggplot2(mpg, aes(class))
ggplot(mpg, aes(class))
ggplot(mpg, aes(class)) + geom_bar
ggplot(mpg, aes(class)) + geom_bar()
testField = collected[3]
histType = testField[1][1]
name = testField[1][2]
specs = testField[1][3]
histType = testField[1]#[1]
name = testField[2]
specs = testField[3]
histType = testField[1] %>% unnest
library tidyr
library(tidyr)
histType = testField[1] %>% flatten
name = testField[2]
specs = testField[3]
library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
specs = rowInfo[3]
library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
specs = rowInfo[3] %>% flatten
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten
as.data.frame(matrix(unlist(barValues), nrow = 2))
as.data.frame(barValues)
as.data.frame(t(as.data.frame(barValues)))
do.call(rbind, barValues)
barVals2 = do.call(rbind, barValues)
View(barVals2)
barVals2 = as.data.frame(do.call(rbind, barValues))
barVals2 = as.data.frame(do.call(cbind, barValues))
View(barVals2)
barVals2 = as.data.frame(do.call(rbind, barValues))
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
flatten(x)
})
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(x[1], x[2])
})
as.data.table(barValues)
do(barValues)
do(as.data.frame(barValues))
as.data.frame(barValues)
as.data.frame(rowInfo[3])
data.frame(barValues)
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(x[1], x[2])
})
data.frame(barValues)
barVals2 = as.data.frame(do.call(cbind, barValues))
barVals2 = do.call(cbind, barValues)
do.call(cbind, barValues)
colGroups = do.call(cbind, barValues)
colGroups = do.call(rbind, barValues)
colGroups = do.call(rowInfo[3] %>% flatten, barValues)
colGroups = do.call(rowInfo[3] %>% flatten, barValues))
testy = rowInfo[3] %>% flatten
#colGroups = do.call(rowInfo[3] %>% flatten, barValues))
#testy = rowInfo[3] %>% flatten
colGroups = do.call(cbind, testy)
data.frame(t(data.frame(barValues)),
row.names = NULL,stringsAsFactors = FALSE
)
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(x[1] %>% flatten, x[2] %>% flatten)
})
data.frame(t(data.frame(barValues)),
row.names = NULL,stringsAsFactors = FALSE
)
data.frame(t(data.frame(barValues)),
row.names = NULL,stringsAsFactors = FALSE
)
data.frame(t(data.frame(barValues)),
row.names = NULL,stringsAsFactors = FALSE
)
data.frame(
transpose(data.frame(barValues)),
row.names = NULL,stringsAsFactors = FALSE
)
data.frame(
transpose(barValues),
row.names = NULL,stringsAsFactors = FALSE
)
data.frame=(matrix(data=barValues,ncol=2,byrow = TRUE))
data.frame(matrix(data=barValues,ncol=2,byrow = TRUE))
data.frame(matrix(data=barValues,ncol=1,byrow = TRUE))
data.frame(matrix(data=barValues,ncol=2,byrow = TRUE))
data.frame(matrix(data=barValues,ncol=10,byrow = TRUE))
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(x[1], x[2])
})
data.frame(matrix(data=barValues,ncol=10,byrow = FALSE))
data.frame(matrix(data=barValues,ncol=2))
matrix(data=barValues, ncol=2, byrow = True)
matrix(data=barValues, ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(x[1] %>% flatten, x[2])
})
matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
transpose(barValues)
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
colVals = transpose(barValues)
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
colVals = data.frame(transpose(barValues))
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
colVals = transpose(barValues)
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
colVals = matrix(transpose(barValues), ncol = 2)
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
matrix(transpose(barValues), ncol = 2)
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
as.data.frame(matrix(transpose(barValues), nrow = 2))
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
as.data.frame(transpose(barValues))
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
# Purrr transpose will take your row lists and convert them to column lists
colVals = transpose(barValues)
#matrix(data=barValues,ncol=2, byrow =TRUE)
#data.frame(matrix(data=barValues,ncol=2))
colVals
colVals[1]
as.data.frame(colVals[1],colVals[2])
as.data.frame(col1=colVals[1],col2=colVals[2])
as.data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
colVals[1]
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
colVals[1] %>% flatten
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
col1 = colVals[1] %>% flatten
#data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
col1 = colVals[1]
#data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
col1 = colVals[1] %>% flatten
#data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
col1 = c(colVals[1] %>% flatten)
#data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
col1 = c(colVals[1] %>% flatten)
#data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
col1 = colVals[1] %>% flatten
col2 colVals[2] %>% flatten
col1 = colVals[1] %>% flatten
col2 = colVals[2] %>% flatten
#data.frame(col1=colVals[1] %>% flatten, col2=colVals[2] %>% flatten)
#data.frame(col1=c(colVals[1]),col2=c(colVals[2]))
drop(data.frame)
data.frame(col1, col2)
data.frame(x=col1, y=col2)
cbind(x=col1, y=col2)
datframe = cbind(x=col1, y=col2)
rbind(x=col1, y=col2)
barValues %>% bind_rows()
barValues %>% bind_rows() %>% select("counts", "value")
barValues %>% bind_rows() %>% select("counts", "value")
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
rbind(x[1] %>% flatten, x[2] %>% flatten )
})
barValues %>% bind_rows() %>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
rbind(rowCount = x[1] %>% flatten, rowVal = x[2] %>% flatten )
})
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() #%>% select("counts", "value")
barValues %>% bind_rows() %>% select("counts", "value")
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
(rowCount = x[1] %>% flatten, rowVal = x[2] %>% flatten)
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(rowCount = x[1] %>% flatten, rowVal = x[2] %>% flatten)
})
barValues %>% map(flatten) %>% bind_rows()
#library(tidyr)
rowInfo = testField[1] %>% flatten
histType = rowInfo[1]
name = rowInfo[2]
barValues = rowInfo[3] %>% flatten %>% map(function(x) {
c(rowName = x[1] %>% flatten, rowBucketCounts = x[2] %>% flatten)
})
barValues %>% map(flatten) %>% bind_rows()
prepped = barValues %>% map(flatten) %>% bind_rows()
ggplot(data=prepped, aes(x=rowName, y=rowBucketCounts)) + geom_bar()
prepped = barValues %>% map(flatten) %>% bind_rows()
ggplot(data=prepped, aes(x=rowName, y=rowBucketCounts)) + geom_bar(stat="identity")
prepped = barValues %>% map(flatten) %>% bind_rows()
ggplot(data=prepped, aes(x=rowName, y=rowBucketCounts)) + geom_bar(stat="identity", width=0.2)
prepped
collected
install.packages("plotly")
q()
setwd("/home/gchurch/R/packages/sparkedatools")
devtools::document()
:q
q()
